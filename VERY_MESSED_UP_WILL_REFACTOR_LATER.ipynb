{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/panyutsriwirote/NLPSysProject.git\n",
        "# %cd NLPSysProject\n",
        "\n",
        "# Uncomment this if you want to re-split the dataset\n",
        "# !python preprocess.py"
      ],
      "metadata": {
        "id": "-mc5ZxKnXTSe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "MOsHUjgdIrIW"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers==4.9.2 seqeval -q\n",
        "!pip install sentencepiece -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zVvslsfMIrIh"
      },
      "outputs": [],
      "source": [
        "LIMIT = 10\n",
        "encoder = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
        "batch_size = 16\n",
        "num_epoch = 50\n",
        "limit_n_tokens = 200\n",
        "save=\"no\"\n",
        "#save=(\"no\",\"epoch\", or \"step\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "vp1CwHZ0sKm7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from transformers import (\n",
        "    AutoModel, AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    TrainingArguments, Trainer,\n",
        "    DataCollatorForTokenClassification\n",
        ")\n",
        "\n",
        "from datasets import (\n",
        "    load_dataset, load_metric,\n",
        "    Dataset,\n",
        "    DatasetDict,\n",
        "    Features, Sequence, ClassLabel, Value\n",
        ")\n",
        "from sklearn.metrics import classification_report\n",
        "from ast import literal_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSp5KGBKJRQ0",
        "outputId": "3515e07a-9cd0-452c-bbe4-5895920a1d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/616a9e2dfc52e9d019b75d219ed800a27158ed299bd4fad91363110fe93dfce1.27c4f6581fbedf3d12e9fae96d4fbb8bc3064cd88ae545414e7cffc7c5bbc52f\n",
            "Model config CamembertConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"camembert\",\n",
            "  \"num_attention_head\": 12,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.9.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 25005\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1eda265bdd85935f17c4e85e9c28e56154e1f50fc8488af73c1b055ceddf292b.a049314b098e88fb885e807c4ac10975e0472235845475ad6b2cf0792902ca69\n",
            "Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of CamembertModel were initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use CamembertModel for predictions without further training.\n",
            "loading configuration file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/616a9e2dfc52e9d019b75d219ed800a27158ed299bd4fad91363110fe93dfce1.27c4f6581fbedf3d12e9fae96d4fbb8bc3064cd88ae545414e7cffc7c5bbc52f\n",
            "Model config CamembertConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"camembert\",\n",
            "  \"num_attention_head\": 12,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.9.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 25005\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/sentencepiece.bpe.model from cache at /root/.cache/huggingface/transformers/723940ae01a5606e15164abf96f0ab7c04305fcd51888f3ef83d89950f5d6bfa.0083544422c6efb7b34819bf9daacd1963043dc7f6ac978929e1c28857ac8252\n",
            "loading file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/be4bffb4d63c772bad4c531d0cdefc41fe7d056d1954177e9bc7e8975c73a163.13700dc3e64ff4e23d6d8686cf822960ccbe7834db8199e4452261ff8a2df1f4\n",
            "loading configuration file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/616a9e2dfc52e9d019b75d219ed800a27158ed299bd4fad91363110fe93dfce1.27c4f6581fbedf3d12e9fae96d4fbb8bc3064cd88ae545414e7cffc7c5bbc52f\n",
            "Model config CamembertConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"camembert\",\n",
            "  \"num_attention_head\": 12,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.9.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 25005\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/616a9e2dfc52e9d019b75d219ed800a27158ed299bd4fad91363110fe93dfce1.27c4f6581fbedf3d12e9fae96d4fbb8bc3064cd88ae545414e7cffc7c5bbc52f\n",
            "Model config CamembertConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"camembert\",\n",
            "  \"num_attention_head\": 12,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.9.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 25005\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_kVBTvqAolmI"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"our_model/train.tsv\", sep='\\t')\n",
        "dev_df = pd.read_csv(\"our_model/dev.tsv\", sep='\\t')\n",
        "test_df = pd.read_csv(\"our_model/test.tsv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"tokens\"] = train_df[\"tokens\"].apply(literal_eval)\n",
        "dev_df[\"tokens\"] = dev_df[\"tokens\"].apply(literal_eval)\n",
        "test_df[\"tokens\"] = test_df[\"tokens\"].apply(literal_eval)\n",
        "\n",
        "labelize = lambda x: [h if h == \"OUT_OF_RANGE\" or -LIMIT <= int(h) <= LIMIT else \"OUT_OF_RANGE\" for h in literal_eval(x)]\n",
        "\n",
        "train_df[\"rel_heads\"] = train_df[\"rel_heads\"].apply(labelize)\n",
        "dev_df[\"rel_heads\"] = dev_df[\"rel_heads\"].apply(labelize)\n",
        "test_df[\"rel_heads\"] = test_df[\"rel_heads\"].apply(labelize)"
      ],
      "metadata": {
        "id": "pI__CH7lHi2e"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "nTchl4Cmww5K"
      },
      "outputs": [],
      "source": [
        "train = train_df[[\"tokens\",\"rel_heads\"]].to_dict(orient=\"series\")\n",
        "dev = dev_df[[\"tokens\",\"rel_heads\"]].to_dict(orient=\"series\")\n",
        "test = test_df[[\"tokens\",\"rel_heads\"]].to_dict(orient=\"series\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "aGoymAZXM3oA"
      },
      "outputs": [],
      "source": [
        "rel_heads = [str(l) for l in range(-LIMIT, LIMIT+1)] + [\"OUT_OF_RANGE\"]\n",
        "features = Features({\n",
        "    \"tokens\": Sequence(Value('string')),\n",
        "    \"rel_heads\": Sequence(feature=ClassLabel(names=rel_heads))\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "kAqXek3ZDIQQ"
      },
      "outputs": [],
      "source": [
        "data = DatasetDict({\n",
        "    'train': Dataset.from_dict(train,features=features), \n",
        "    'dev': Dataset.from_dict(dev,features=features),\n",
        "    'test': Dataset.from_dict(test,features=features)\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Us7VZeI_MNUj"
      },
      "outputs": [],
      "source": [
        "label_all_tokens = True\n",
        "#True: all tokens have same label as original word\n",
        "#False: only the first token have same label as original word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "vc0BSBLIIrJQ"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    tokens = [tokenizer.convert_ids_to_tokens(x) for x in tokenized_inputs[\"input_ids\"] ]\n",
        "    ids=[]\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"rel_heads\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # Set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "        ids.append(word_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    tokenized_inputs[\"word_ids\"] = ids\n",
        "    tokenized_inputs[\"tokens_bert\"] = tokens\n",
        "    return tokenized_inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "87067371af9a4f60bff522210324e994",
            "479310b32c1d4bc289797ae853f17db7",
            "6b2c70418cff4a03aebd75aa575b17e6",
            "464c2610e2de4b46b15a0ed3356cfd72",
            "6d60c272a2754aa1b3f368f691d74e29",
            "ae8aeb2c8c034c3aa3a136ce45e3d501",
            "ee93fed9984b4ee399b4c3db3207a1e2",
            "e39dd3ac92f54a07aac3775ee9a53f50",
            "168ed74288ee45ad8d0b4627a40d8eb7",
            "a43be7c8fd8445f88dee2e4963d5b6cc",
            "676ea096514a4c0a823943b76bc20e2d",
            "689cc3e94b9440a4b801114b3c2564f6",
            "c349e7664a4d44e4ba44ebba2e57a6a4",
            "ae4a4b7d5cb846d19e2a05e3e22ea683",
            "e047cac1db6a45e882bf6718514a4fe7",
            "4665aedd8b2a41f999c74c317fa7ebc5",
            "e7ffcb4359a849538db1d657b7416e67",
            "6cb6df574e0447a59892aea4e9593542",
            "b301d4d884864850a0b62fa93d7abee8",
            "6f822d5e6cf844389b9288affd105073",
            "6860b685251447d0927e6b2d1ec6dc7d",
            "e2ad8523473c4b99903cfeb894835986",
            "28a2f4b58fef4e9ab875ba60c2190af3",
            "a8fc22b346264e1986d51f2654e8b8d6",
            "82c0d2fb347343f69a1a77dc2e344235",
            "137dc7bb7a854793bba19c2decddbf62",
            "972f7b182f4749028fbd77e0f953dd89",
            "b71f361fd6a94df58e7b6780b0997754",
            "253d57bd60b74e47857ee529a0f970e2",
            "0710d51e441a4b1a82977e3a53d00313",
            "e54e89f2e094428e8f2ec7bb47a7778f",
            "1642feaa21a24888a931a12db13a17a0",
            "1765e0f66a0545ea972554d6e4ccafdb"
          ]
        },
        "id": "fRM6NFMO82XL",
        "outputId": "410c3061-23b0-4578-8626-3e0ad684419d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87067371af9a4f60bff522210324e994"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "689cc3e94b9440a4b801114b3c2564f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28a2f4b58fef4e9ab875ba60c2190af3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_datasets = data.map(tokenize_and_align_labels, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "nZf4a6Or5hwV"
      },
      "outputs": [],
      "source": [
        "label_list = data['train'].features[\"rel_heads\"].feature.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlqNaB8jIrJW",
        "outputId": "25838f79-9bc8-40ed-8ff1-4777d771f18f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/616a9e2dfc52e9d019b75d219ed800a27158ed299bd4fad91363110fe93dfce1.27c4f6581fbedf3d12e9fae96d4fbb8bc3064cd88ae545414e7cffc7c5bbc52f\n",
            "Model config CamembertConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\",\n",
            "    \"14\": \"LABEL_14\",\n",
            "    \"15\": \"LABEL_15\",\n",
            "    \"16\": \"LABEL_16\",\n",
            "    \"17\": \"LABEL_17\",\n",
            "    \"18\": \"LABEL_18\",\n",
            "    \"19\": \"LABEL_19\",\n",
            "    \"20\": \"LABEL_20\",\n",
            "    \"21\": \"LABEL_21\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_14\": 14,\n",
            "    \"LABEL_15\": 15,\n",
            "    \"LABEL_16\": 16,\n",
            "    \"LABEL_17\": 17,\n",
            "    \"LABEL_18\": 18,\n",
            "    \"LABEL_19\": 19,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_20\": 20,\n",
            "    \"LABEL_21\": 21,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"camembert\",\n",
            "  \"num_attention_head\": 12,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.9.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 25005\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1eda265bdd85935f17c4e85e9c28e56154e1f50fc8488af73c1b055ceddf292b.a049314b098e88fb885e807c4ac10975e0472235845475ad6b2cf0792902ca69\n",
            "Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertForTokenClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(encoder, num_labels=len(label_list))\n",
        "model_name = encoder.split(\"/\")[-1]\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"dep_parsing_as_token_class\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epoch,\n",
        "    save_strategy=save,\n",
        "    # save_total_limit = 2,\n",
        "    # load_best_model_at_end=True,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "metric = load_metric(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "UmvbnJ9JIrJd"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "imY1oC3SIrJf"
      },
      "outputs": [],
      "source": [
        "HEAD_CLASSIFIER = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['dev'],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3tlotgBzMNUm",
        "outputId": "c91d83a8-96fd-4b66-d340-5ffb4787e993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running training *****\n",
            "  Num examples = 735\n",
            "  Num Epochs = 50\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2300\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2300' max='2300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2300/2300 10:33, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.882928</td>\n",
              "      <td>0.195550</td>\n",
              "      <td>0.189917</td>\n",
              "      <td>0.192692</td>\n",
              "      <td>0.469753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.426266</td>\n",
              "      <td>0.389183</td>\n",
              "      <td>0.417362</td>\n",
              "      <td>0.402780</td>\n",
              "      <td>0.584937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.178168</td>\n",
              "      <td>0.473236</td>\n",
              "      <td>0.506065</td>\n",
              "      <td>0.489101</td>\n",
              "      <td>0.638863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.038746</td>\n",
              "      <td>0.536551</td>\n",
              "      <td>0.573161</td>\n",
              "      <td>0.554252</td>\n",
              "      <td>0.672472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.948393</td>\n",
              "      <td>0.581042</td>\n",
              "      <td>0.608795</td>\n",
              "      <td>0.594595</td>\n",
              "      <td>0.697525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.897234</td>\n",
              "      <td>0.600144</td>\n",
              "      <td>0.632676</td>\n",
              "      <td>0.615981</td>\n",
              "      <td>0.709441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.841248</td>\n",
              "      <td>0.620267</td>\n",
              "      <td>0.652009</td>\n",
              "      <td>0.635742</td>\n",
              "      <td>0.727314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.807757</td>\n",
              "      <td>0.637026</td>\n",
              "      <td>0.662623</td>\n",
              "      <td>0.649573</td>\n",
              "      <td>0.735105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.791494</td>\n",
              "      <td>0.654366</td>\n",
              "      <td>0.678923</td>\n",
              "      <td>0.666419</td>\n",
              "      <td>0.745952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.776321</td>\n",
              "      <td>0.663623</td>\n",
              "      <td>0.688779</td>\n",
              "      <td>0.675967</td>\n",
              "      <td>0.753284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.040200</td>\n",
              "      <td>0.777119</td>\n",
              "      <td>0.671324</td>\n",
              "      <td>0.692191</td>\n",
              "      <td>0.681598</td>\n",
              "      <td>0.755881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.040200</td>\n",
              "      <td>0.758585</td>\n",
              "      <td>0.684346</td>\n",
              "      <td>0.704321</td>\n",
              "      <td>0.694190</td>\n",
              "      <td>0.765506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.040200</td>\n",
              "      <td>0.770055</td>\n",
              "      <td>0.695090</td>\n",
              "      <td>0.713798</td>\n",
              "      <td>0.704320</td>\n",
              "      <td>0.772991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.040200</td>\n",
              "      <td>0.759456</td>\n",
              "      <td>0.693855</td>\n",
              "      <td>0.719105</td>\n",
              "      <td>0.706255</td>\n",
              "      <td>0.776658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.040200</td>\n",
              "      <td>0.778396</td>\n",
              "      <td>0.696947</td>\n",
              "      <td>0.718347</td>\n",
              "      <td>0.707486</td>\n",
              "      <td>0.779407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.040200</td>\n",
              "      <td>0.773998</td>\n",
              "      <td>0.699558</td>\n",
              "      <td>0.720243</td>\n",
              "      <td>0.709750</td>\n",
              "      <td>0.777574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.040200</td>\n",
              "      <td>0.782110</td>\n",
              "      <td>0.712904</td>\n",
              "      <td>0.726687</td>\n",
              "      <td>0.719730</td>\n",
              "      <td>0.788268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.040200</td>\n",
              "      <td>0.778496</td>\n",
              "      <td>0.708318</td>\n",
              "      <td>0.732752</td>\n",
              "      <td>0.720328</td>\n",
              "      <td>0.789031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.040200</td>\n",
              "      <td>0.800355</td>\n",
              "      <td>0.715708</td>\n",
              "      <td>0.735785</td>\n",
              "      <td>0.725607</td>\n",
              "      <td>0.789184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.040200</td>\n",
              "      <td>0.797924</td>\n",
              "      <td>0.722736</td>\n",
              "      <td>0.741092</td>\n",
              "      <td>0.731799</td>\n",
              "      <td>0.793156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.040200</td>\n",
              "      <td>0.802747</td>\n",
              "      <td>0.712038</td>\n",
              "      <td>0.737680</td>\n",
              "      <td>0.724632</td>\n",
              "      <td>0.794531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.814104</td>\n",
              "      <td>0.715285</td>\n",
              "      <td>0.736164</td>\n",
              "      <td>0.725574</td>\n",
              "      <td>0.793767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.831232</td>\n",
              "      <td>0.711234</td>\n",
              "      <td>0.731994</td>\n",
              "      <td>0.721465</td>\n",
              "      <td>0.789337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.820849</td>\n",
              "      <td>0.718439</td>\n",
              "      <td>0.739955</td>\n",
              "      <td>0.729038</td>\n",
              "      <td>0.795142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.833005</td>\n",
              "      <td>0.720148</td>\n",
              "      <td>0.738438</td>\n",
              "      <td>0.729178</td>\n",
              "      <td>0.793614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.841713</td>\n",
              "      <td>0.713605</td>\n",
              "      <td>0.737680</td>\n",
              "      <td>0.725443</td>\n",
              "      <td>0.792392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.849436</td>\n",
              "      <td>0.713187</td>\n",
              "      <td>0.738059</td>\n",
              "      <td>0.725410</td>\n",
              "      <td>0.795295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.862839</td>\n",
              "      <td>0.718382</td>\n",
              "      <td>0.740713</td>\n",
              "      <td>0.729377</td>\n",
              "      <td>0.797128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.857327</td>\n",
              "      <td>0.719588</td>\n",
              "      <td>0.742229</td>\n",
              "      <td>0.730733</td>\n",
              "      <td>0.796059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.857785</td>\n",
              "      <td>0.723100</td>\n",
              "      <td>0.746399</td>\n",
              "      <td>0.734564</td>\n",
              "      <td>0.799725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.875906</td>\n",
              "      <td>0.718372</td>\n",
              "      <td>0.742608</td>\n",
              "      <td>0.730289</td>\n",
              "      <td>0.798656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.886438</td>\n",
              "      <td>0.720853</td>\n",
              "      <td>0.742987</td>\n",
              "      <td>0.731753</td>\n",
              "      <td>0.798503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.883130</td>\n",
              "      <td>0.720177</td>\n",
              "      <td>0.741471</td>\n",
              "      <td>0.730669</td>\n",
              "      <td>0.799725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.886996</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.741092</td>\n",
              "      <td>0.729750</td>\n",
              "      <td>0.800642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.893431</td>\n",
              "      <td>0.721281</td>\n",
              "      <td>0.742608</td>\n",
              "      <td>0.731789</td>\n",
              "      <td>0.799878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.896312</td>\n",
              "      <td>0.718464</td>\n",
              "      <td>0.744882</td>\n",
              "      <td>0.731435</td>\n",
              "      <td>0.798656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.903897</td>\n",
              "      <td>0.725440</td>\n",
              "      <td>0.750190</td>\n",
              "      <td>0.737607</td>\n",
              "      <td>0.802780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.913135</td>\n",
              "      <td>0.722100</td>\n",
              "      <td>0.745641</td>\n",
              "      <td>0.733681</td>\n",
              "      <td>0.801100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.910955</td>\n",
              "      <td>0.723834</td>\n",
              "      <td>0.747157</td>\n",
              "      <td>0.735311</td>\n",
              "      <td>0.802475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.916684</td>\n",
              "      <td>0.722080</td>\n",
              "      <td>0.747536</td>\n",
              "      <td>0.734587</td>\n",
              "      <td>0.801405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.924017</td>\n",
              "      <td>0.721468</td>\n",
              "      <td>0.745262</td>\n",
              "      <td>0.733172</td>\n",
              "      <td>0.800336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.926744</td>\n",
              "      <td>0.720777</td>\n",
              "      <td>0.745641</td>\n",
              "      <td>0.732998</td>\n",
              "      <td>0.799572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.927520</td>\n",
              "      <td>0.718269</td>\n",
              "      <td>0.742229</td>\n",
              "      <td>0.730052</td>\n",
              "      <td>0.797739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.114900</td>\n",
              "      <td>0.931142</td>\n",
              "      <td>0.721691</td>\n",
              "      <td>0.744124</td>\n",
              "      <td>0.732736</td>\n",
              "      <td>0.799572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.114900</td>\n",
              "      <td>0.934235</td>\n",
              "      <td>0.719633</td>\n",
              "      <td>0.743366</td>\n",
              "      <td>0.731307</td>\n",
              "      <td>0.801405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.114900</td>\n",
              "      <td>0.937036</td>\n",
              "      <td>0.721366</td>\n",
              "      <td>0.744882</td>\n",
              "      <td>0.732935</td>\n",
              "      <td>0.801100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.114900</td>\n",
              "      <td>0.938106</td>\n",
              "      <td>0.721305</td>\n",
              "      <td>0.745641</td>\n",
              "      <td>0.733271</td>\n",
              "      <td>0.801405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.114900</td>\n",
              "      <td>0.942413</td>\n",
              "      <td>0.718945</td>\n",
              "      <td>0.743745</td>\n",
              "      <td>0.731135</td>\n",
              "      <td>0.800183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.114900</td>\n",
              "      <td>0.940013</td>\n",
              "      <td>0.724430</td>\n",
              "      <td>0.746399</td>\n",
              "      <td>0.735250</td>\n",
              "      <td>0.802475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.114900</td>\n",
              "      <td>0.940822</td>\n",
              "      <td>0.723529</td>\n",
              "      <td>0.746020</td>\n",
              "      <td>0.734602</td>\n",
              "      <td>0.802016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -1 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -2 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -3 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -6 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -4 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OUT_OF_RANGE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 4 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -5 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -7 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -9 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -10 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -8 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 157\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2300, training_loss=0.3766581328018852, metrics={'train_runtime': 633.8146, 'train_samples_per_second': 57.982, 'train_steps_per_second': 3.629, 'total_flos': 1474600875111168.0, 'train_loss': 0.3766581328018852, 'epoch': 50.0})"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "HEAD_CLASSIFIER.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(head_classifier, label_classifier, test_set):\n",
        "    predictions, labels, _ = head_classifier.predict(test_set)\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    bert_prediction = [\n",
        "    [(id, token, prediction) for (id, token, prediction) in zip(row_id, row_token,row_predictions) ]\n",
        "        for row_id, row_token, row_predictions in zip(tokenized_datasets['test']['word_ids'],tokenized_datasets['test']['tokens_bert'],predictions)\n",
        "    ]\n",
        "\n",
        "    gold_label = [\n",
        "        [label for label in row_label ] for row_label in tokenized_datasets['test']['rel_heads']\n",
        "    ]\n",
        "\n",
        "    wrap_predict = [] \n",
        "    for row in bert_prediction:\n",
        "        predict_row = []\n",
        "        previous_word=None\n",
        "        for item in row:\n",
        "            if(item[0] is not None):\n",
        "                #skip special token\n",
        "                if(item[0] != previous_word):\n",
        "                    predict_row.append(item[-1])\n",
        "                    previous_word = item[0]\n",
        "        wrap_predict.append(predict_row)\n",
        "    \n",
        "    def flatten(t):\n",
        "        return [item for sublist in t for item in sublist]\n",
        "    flat_true_predictions = flatten(wrap_predict)\n",
        "    flat_true_labels = flatten(gold_label)\n",
        "\n",
        "    # result = classification_report(flat_true_labels,flat_true_predictions,output_dict=True,labels=label_list)\n",
        "    # result_df = pd.DataFrame(result).transpose()\n",
        "    # display(result_df)\n",
        "\n",
        "    correct, total = 0, 0\n",
        "    for pred, gold in zip(flat_true_predictions, flat_true_labels):\n",
        "        if pred != \"OUT_OF_RANGE\" and pred == gold:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "    UAS = (correct / total) * 100\n",
        "\n",
        "    predictions, labels, _ = label_classifier.predict(test_set)\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    bert_prediction = [\n",
        "    [(id, token, prediction) for (id, token, prediction) in zip(row_id, row_token,row_predictions) ]\n",
        "        for row_id, row_token, row_predictions in zip(tokenized_datasets['test']['word_ids'],tokenized_datasets['test']['tokens_bert'],predictions)\n",
        "    ]\n",
        "\n",
        "    gold_label = [\n",
        "        [label for label in row_label ] for row_label in tokenized_datasets['test']['rel_heads']\n",
        "    ]\n",
        "\n",
        "    wrap_predict = [] \n",
        "    for row in bert_prediction:\n",
        "        predict_row = []\n",
        "        previous_word=None\n",
        "        for item in row:\n",
        "            if(item[0] is not None):\n",
        "                #skip special token\n",
        "                if(item[0] != previous_word):\n",
        "                    predict_row.append(item[-1])\n",
        "                    previous_word = item[0]\n",
        "        wrap_predict.append(predict_row)\n",
        "    flat_true_predictions = flatten(wrap_predict)\n",
        "    flat_true_labels = flatten(gold_label)\n",
        "\n",
        "    # result = classification_report(flat_true_labels,flat_true_predictions,output_dict=True,labels=label_list)\n",
        "    # result_df = pd.DataFrame(result).transpose()\n",
        "    # display(result_df)\n",
        "\n",
        "    correct, total = 0, 0\n",
        "    for pred, gold in zip(flat_true_predictions, flat_true_labels):\n",
        "        if pred == gold:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "    LAS = correct / total\n",
        "\n",
        "    return UAS, LAS"
      ],
      "metadata": {
        "id": "xitn8hn45PSG"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(HEAD_CLASSIFIER, LABEL_CLASSIFIER, tokenized_datasets[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "id": "mc2bBRfy9bDa",
        "outputId": "31e8b6c0-9137-4c6e-97fc-208d33cc5eda"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: rel_heads, tokens, word_ids, tokens_bert.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 158\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 51:47]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -1 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -2 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -5 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OUT_OF_RANGE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -3 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -4 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -8 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -7 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 4 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -6 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -9 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -10 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(78.69051227644741, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "87067371af9a4f60bff522210324e994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_479310b32c1d4bc289797ae853f17db7",
              "IPY_MODEL_6b2c70418cff4a03aebd75aa575b17e6",
              "IPY_MODEL_464c2610e2de4b46b15a0ed3356cfd72"
            ],
            "layout": "IPY_MODEL_6d60c272a2754aa1b3f368f691d74e29"
          }
        },
        "479310b32c1d4bc289797ae853f17db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae8aeb2c8c034c3aa3a136ce45e3d501",
            "placeholder": "",
            "style": "IPY_MODEL_ee93fed9984b4ee399b4c3db3207a1e2",
            "value": "100%"
          }
        },
        "6b2c70418cff4a03aebd75aa575b17e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e39dd3ac92f54a07aac3775ee9a53f50",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_168ed74288ee45ad8d0b4627a40d8eb7",
            "value": 1
          }
        },
        "464c2610e2de4b46b15a0ed3356cfd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a43be7c8fd8445f88dee2e4963d5b6cc",
            "placeholder": "",
            "style": "IPY_MODEL_676ea096514a4c0a823943b76bc20e2d",
            "value": " 1/1 [00:00&lt;00:00,  4.62ba/s]"
          }
        },
        "6d60c272a2754aa1b3f368f691d74e29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae8aeb2c8c034c3aa3a136ce45e3d501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee93fed9984b4ee399b4c3db3207a1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e39dd3ac92f54a07aac3775ee9a53f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "168ed74288ee45ad8d0b4627a40d8eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a43be7c8fd8445f88dee2e4963d5b6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "676ea096514a4c0a823943b76bc20e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "689cc3e94b9440a4b801114b3c2564f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c349e7664a4d44e4ba44ebba2e57a6a4",
              "IPY_MODEL_ae4a4b7d5cb846d19e2a05e3e22ea683",
              "IPY_MODEL_e047cac1db6a45e882bf6718514a4fe7"
            ],
            "layout": "IPY_MODEL_4665aedd8b2a41f999c74c317fa7ebc5"
          }
        },
        "c349e7664a4d44e4ba44ebba2e57a6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7ffcb4359a849538db1d657b7416e67",
            "placeholder": "",
            "style": "IPY_MODEL_6cb6df574e0447a59892aea4e9593542",
            "value": "100%"
          }
        },
        "ae4a4b7d5cb846d19e2a05e3e22ea683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b301d4d884864850a0b62fa93d7abee8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f822d5e6cf844389b9288affd105073",
            "value": 1
          }
        },
        "e047cac1db6a45e882bf6718514a4fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6860b685251447d0927e6b2d1ec6dc7d",
            "placeholder": "",
            "style": "IPY_MODEL_e2ad8523473c4b99903cfeb894835986",
            "value": " 1/1 [00:00&lt;00:00, 12.58ba/s]"
          }
        },
        "4665aedd8b2a41f999c74c317fa7ebc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ffcb4359a849538db1d657b7416e67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb6df574e0447a59892aea4e9593542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b301d4d884864850a0b62fa93d7abee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f822d5e6cf844389b9288affd105073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6860b685251447d0927e6b2d1ec6dc7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ad8523473c4b99903cfeb894835986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28a2f4b58fef4e9ab875ba60c2190af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8fc22b346264e1986d51f2654e8b8d6",
              "IPY_MODEL_82c0d2fb347343f69a1a77dc2e344235",
              "IPY_MODEL_137dc7bb7a854793bba19c2decddbf62"
            ],
            "layout": "IPY_MODEL_972f7b182f4749028fbd77e0f953dd89"
          }
        },
        "a8fc22b346264e1986d51f2654e8b8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b71f361fd6a94df58e7b6780b0997754",
            "placeholder": "",
            "style": "IPY_MODEL_253d57bd60b74e47857ee529a0f970e2",
            "value": "100%"
          }
        },
        "82c0d2fb347343f69a1a77dc2e344235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0710d51e441a4b1a82977e3a53d00313",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e54e89f2e094428e8f2ec7bb47a7778f",
            "value": 1
          }
        },
        "137dc7bb7a854793bba19c2decddbf62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1642feaa21a24888a931a12db13a17a0",
            "placeholder": "",
            "style": "IPY_MODEL_1765e0f66a0545ea972554d6e4ccafdb",
            "value": " 1/1 [00:00&lt;00:00, 12.96ba/s]"
          }
        },
        "972f7b182f4749028fbd77e0f953dd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71f361fd6a94df58e7b6780b0997754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253d57bd60b74e47857ee529a0f970e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0710d51e441a4b1a82977e3a53d00313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e54e89f2e094428e8f2ec7bb47a7778f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1642feaa21a24888a931a12db13a17a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1765e0f66a0545ea972554d6e4ccafdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}